- 단순하게 몇 개 정도의 차원으로 이루어진 데이터에 대해서는 **FCN(Fully Connected Network)** 구조의 딥러닝 학습이 기존의 통계방법이나 다른 머신러닝 방법 만큼이나 잘 학습이 됨  

- 그런데 **이미지 인식**이나 **음성**, **자연어 인식**과 같은 작업을 위해서는 훨씬 더 복잡한 데이터의 특징을 잡아내야함  

- 이를 위해서 보다 효율적이고 효과적인 구조가 필요함  

이번 토픽에서 각 데이터 종류별로 특성에 최적화된 뉴럴 네트워크 구조를 알아보자  

- CNN : 이미지 데이터 특징에 최적화  

- RNN : 시계열 데이터 특징에 최적화 ex) 주가 데이터, 센서 데이터 등 순서가 있는 데이터  

- AutoEncoder : 차원 축소에 유용 ex) 고차원 데이터의 차원축소에 유용, 생성형 모델이나 언어모델



## CNN이란? 

**CNN : Convolutional Neural Network** 

고양이와 강아지 모델을 구별하는 딥러닝 모델을 만든다고 하자 

우선 이미지 데이터를 컴퓨터가 인식할 수 있는 형태로 표현하는데 기본적으로 **비트맵**이라는 형태로 표현  

**비트맵**은 가로 세로 크기가 있는 영역에 **픽셀**이라고 부르는 **점**을 찍어서 표현  

각 픽셀은 **픽셀값**이라 부르는 강도를 가지고 있음 

![](/image/1-48.PNG)  

그렇다면 컬러이미지는 어떻게 표현할까?  

빛의 3원색인 **빨강**, **파랑**, **초록**의 색상의 강도를 나눠서 표현함  

**채널**이라고 부르는 동일한 크기의 영역 각각에 빨강 파랑 초록의 강도를 **0에서 255**까지 표현함  


![](/image/1-49.PNG)  

따라서 이미지의 크기는 **가로** * **세로** * **채널 수**로 구할 수 있음 

![](/image/1-50.PNG)  


이미지 데이터를 Fully Connected Network로 학습하려면?  


데이터를 일자로 쭉펴서 픽셀 하나하나의 값을 가지고 학습을 전부해야함  


![](/image/1-51.PNG)  
  
가로 세로 픽셀이 각각 10 by 10인 컬러 이미지의 경우에 300픽셀이 300차원의 벡터 x가 됨  
하지만 이렇게 하면 지금첢처럼 이미지가 조금만 복잡해져도 좋은 성능을 ㅐㄴ기 어려움

이미지의 지역적 특성을 반영하지 못함

### 이미지의 지역적 특성이란? 
이미지 내에서 객체나 형태와 같은 특징이 부분적으로 나타나는 것 

![](/image/1-52.PNG)  

  
그런데 이미지는 작은 지역의 특징이고 큰 형태를 만들고 2차원 구조를 만들게 됨  

이것을 FCN로 인식한다는 것은 가중치를 다 따로 따로 학습한다는 의미  


인식해야하는 특성에 비해 학습시켜야 하는 가중치가 과도하게 많아서 **비효율적**  


![](/image/1-53.PNG)  

  

그런데 어떠한 이미지에 보편적인 특징이 위치마다 다 다르진 않을 것임 즉, **중복**이 됨 

이러한 비효율을 개선하기 위해서   
지역적 특성을 추출할 수 있는 **적당히 작은 고정된 크기**로 **묶어서 학습**하자는것이 **CNN**의 시작! 

이렇게 묶인 공통적인 지역적 특성을 추출할 수 있는 단위를 **Convolution Filter**라고 함 

## Convolutional Filter
- Kernel이라고도 부름
- 이미지 크기보다 작은 크기의 행렬 
- 각각의 행렬값이 딥러닝의 학습파라미터인 Weight임 
- 이미지에서 Conv Filter 행렬 크기만큼의 영역에 대해 계산을 수행
- 이미지 내의 패턴이나 특징을 효과적으로 인식 
- **Convolution Filter를 이용한 연산**을 **Convolution 연산**이라고 부름  

![](/image/1-54.PNG)  

  

이러한 **Convolution 연산**을 포함한 **Convolutinal Layer**로 이루어진 네트워크 구조를 **Convolutional Neural Network(CNN)**라고 함  


그러면 **CNN**을 어떤 분야에서 많이 사용할까?  

![](/image/1-55.PNG)  

  

## Convoluional Network 구조 

![](/image/1-56.PNG)  
  
   
앞으로 배움 


## Convolutional Layer 

: 컨볼루션 연산이 수행되는 레이어 

입력 데이터에 커널이라는 필터를 적용하여 값을 계산 

예시) 3 by 3 크기의 필터가 있다고 하자 
연산을 위해서 이 작은 조각을 입력데이터의 좌상단에 대응시키는것ㅇ로 시작 
입력데이터의 숫자와 필터에 있는 값을 같은 위치에 있는 값과 곱하고 다 더함 

1-57

이렇게 곱한 값들을 다 더한다고 해서 한국어로 합성곱이라고 부르기도 함 

실제로 cnn에서 컨볼ㄹ루션 레이어를 사용할떄에는 입력과 출력의 채널수를 고ㅎ려해야함
입력레이어 r,g,b,처럼 채널이 3개라고 하면 커널으 ㅣ채널도 3개가됨 
따라서 컨볼류션 연산의 최종결과는 채널별로 구한 값을 모두 더하여 계산 

또한 커널 하나에는 최종적으로 더해지는 바이어스 값도 학습됨  

1-58

이러헥 한번의 계산이 끄탄면 한칸식 필터를 옮겨가면서 계산을 해줌 
이걸 Feature Map(특성 맵)이라고도 함 
실제로 이것이 이미지라기 보다는 입력에 각픽셀에 대응되는 특징을 위치정보를 유지한 순서대로 출력함 
1-59

1-60
그리고 여기 커널에 있느 값들은 고정도니게 아니라 나중에 모델이 데잍러ㅡㄹ 통해 학습하는 파라미터(Weight)이며 이미지의 특성을 가장 잘 파악할 수 있는 방향으로 바꾸미

이러한 컨볼류션 필터의 크기를 바꿀 수도 있음 
이것을 커널 크기(Kernel Size)라고 부름
좀 더 넓은 주변부의 정보를 요약하고 싶다면 커널의 크기가 커지면 됨 

1-61 

그리고 지금까지는 커널이 한 칸씩 이동했는데 필터를 몇 칸씩 이동할지 설정할 수도 있음  이걸 스트라이드라고 부름  기본값은 1인데 2가 되면  두 칸씩 이동하게됨 
즉 한칸씩 건너뛰어 계산하게 되므로 출력되는 피쳐맵의 크기가 줄어듬 

1-62

**STRIDE의 직관적 의미**

- Convolution은 주변 정보를 모은다
- Stride로 건너뛰어도, 아예 건너뛴 픽셀은 없다
- Convolution 연산의 복잡도를 줄임 

가장자리의 정보는 상대적으로 덜 반영될 수밖에 없음! 

1-63

이 문제를 해결할 수 있는 방법이 있음 
이미지 가장자리에 임의의 값들을 채워넣어줄 건데 이게 바로 **Padding**이라고 함 

1-64 

보통 이렇게 0으로 채우는 경우가 많음  
가장자리에 padding을 함으로써 입력이미지의 크기 자체가 커지는 효과가 있음
그리고 이미지 가장자리의 정보도 더 반영됨 

1-65  

그렇다면 시각적이미지의 지역적 특성을 추출하는 convolution layer는 어떻게 구성될까?

처음소개에서 외곽선 정보 질감 패턴등 여러가지 시각적 특성을 추출할 수잇다고 언급ㅎㅁ

여러개의 대으오디는 커널들이 필요함 
입력이미지는 커널 수 만큼의 피쳐 맵으로 변환됨
이 한=묶으음 피쳐맵을 추출하는 n개의 커널이 컨볼루셔널 레이어 하나를 구성하는 요소가 됨 


## Pooling layer 

CNN에는 Convolution layer 말고도 Pooling layer라는 특징적인 레이어가 있다고 했음 
pooling layer는 말그대로 pooling연산이 이루어지는 레이어 
목적은 다운 샘플링을 하는것에 있음 

다운샘플링은 동일한 이미지를 좀 더 적은량의 정보로 표현하는 것을 의미 
1-66  

풀링 연산도 이미지의 커널을 옮겨가면서 적용함 보통 스트라이드르 2로 움직임 
마찬가지로 이 영역을 대표하는 값 하나를 출력한느 점은 컨볼류션과 도잉랗
다만 풀리응ㄴ 학습되는 파라미터의 값이 있는것이 아니고 커널의 사이즈와 종류만 존재함 
풀리에슨ㄴ 크게 2가지의 방법이 있음 가장 많이 사용하느 방식은 max 풀링이 있음 

지정된 영역의 값중에서 가장 큰 값을 뽑아냄 
가끔 에버리지 풀링 방법도 사용되는데 에버리지는 영역 내 모든 값의 평균값임 
즉 풀링은 특정영역에서 중요하다고 생각되는 정보만을 남겨서 요약해주는 기능을 함 

풀링을 하면 보통 더 작은 사이즈의 피쳐맵을 얻음 
이렇게 하면 모델의 목잡도를 낮춰 오버피팅을 방지하고 계산량을 줄임 
즉 일반화 능력ㅇ르 향상시킴  

또한 이미지 안에 있는 객체의 크기, 각도, 위치가 조금 변형되어도 인식이 잘 되도 학습 (Invariant to Local translation)

즉, 위치보다는 존재 여부에 더 집중할 수 있게 해줌  
풀링도 마찬가지로 커널 사이즈를 가짐 
보통 2*2 sk 3*3을 사용 
풀링은 피쳐맵의 크기를 줄이기 위해 사용 보통 스트라이드값을 2를 사용하여 절반으로 줄임   
패딩은 대부분 적용하지 않음 

cnn은 이 두가지 레이어를 기본으로 여러조합을 통해레리어를 쌓아올려 구성하게됨 

## 대표적인 CNN 모델 구조 알아보기  

아주 기본적인 이미지 분류 문제를 통해서 대표적인 cnn 모델의 구조와 특징을 살펴보자 

이번시간에는 LeNet이라는 이미지 분류모델을 알아볼거임 

제목을 보면 문서인식을 위한 모델임을 알 수 있음 
1-68
지금 소개할 내용은 미국 우편공사의 우편번호 손글씨를 컴퓨터로 인식하기 위한 연구임

이과정에서 MNIST database가 구축되었음
필기체와 숫자이미지를 모아논 데이터셋 

1-69

모델 구조를 살펴보자 
먼저 첫번재 Con Layer에서는 6개의 5*5크기의 컨러을 사용 이미지이 크기를 유지하기 위해 패딩을 상하좌우 2개씩 적용시켜서 6개의 피쳐맵을 뽑아냄 
그리고 풀리응로 절반을 줄이고 (생략...)
1-70 
1-71

Lenet은 CNN의 선구적인 역할을 함 
이때부터 convolution layer와 pooling의 개념을 도입하여 시각적인특성을 효과적으로 추출하는 방법이 제안되기 시작함

Lenet 모델은 
딥러닝이 다른 기존의 이미지 패턴인식 방법에 비해 더 좋은성능을 낼 수있다는 것을 보여줌
(98%의 정확도)
MNIST데이터셋은 이후에도 여러 딥러닝 모델의 성응을 측정하는 벤치마크로 활용됨  


이외에도 **ImageNet**, **AlexNet**, **VGGNet**, **GoogLeNet**, **ResNet**등이 있음  

